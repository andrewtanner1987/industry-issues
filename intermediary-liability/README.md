# Intermediary liability

## What is it?

An internet intermediary is [a company that facilitiates the use of the Internet (Wikipedia)](https://en.wikipedia.org/wiki/Internet_intermediary). This includes companies that provide the network connection to the internet, such as internet service providers (ISPs), as well as those that provide online services like search engines and social media platforms.

[Intermediary liability](http://cyberlaw.stanford.edu/focus-areas/intermediary-liability) is a legal concept which describes how liable an intermediary is for the content which it stores and transmits. Such content could potentially include hate speech, copyright infringement, or images of abuse. Under some definitions of intermediary liability it would be possible for the owners and employees of intermediaries to be convicted of crimes for content which they personally have had nothing to do with - just because that content passed through their systems.

For the purposes of legal liability, an internet intermediary is an organisation - such as a company or a website - who makes content available online which was not authored by themselves.

For publishers such as Netflix or The Guardian, their content goes through an editorial process before being published. For social media websites such as Twitter and Facebook, as well as platform operators like WordPress.com and eBay and the infrastructure companies which provide the servers and cables making up Internet connectivity, content is often not checked before being published. Intermediary liability is the principle that states the publishing platform is not legally liable for content published by its users.

## Why is it important?

The last few decades have seen an explosion in worldwide communication, mainly due to the connectivity the internet affords. This communication has enabled education to reach those who could not previously access it, and allowed people in repressive regimes to organise and stand up for their human rights. However, this has also been an opportunity to spread illegal content.

So far intermediaries have not been held liable for the content stored in or transmitted through their systems. But global governments are increasingly vocal about the part intermediaries play in assisting with the policing of the internet. In some cases, legal sanctions have been threatened against intermediaries whose systems are used by those abusing their right to free speech.

Some people have made comparisons between internet intermediaries and other providers of communication or transit mechanisms, such as phone companies and highway agencies. They ask the question whether BT should be held liable for telephone calls made to plot terrorist actions. Or whether Highways England have some responsibility to ensure that criminals using its roads to get away from a crime scene are stopped. These comparisons are only useful to a degree.

## What's happening with it?

The UK government has expressed the opinion that intermediaries should be held liable for the content in and moving through their systems. This is directly opposed to articles 12-15 of the [e-Commerce Directive](https://ec.europa.eu/digital-single-market/en/e-commerce-directive) ([see the wording here](http://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32000L0031&from=EN)), the entirity of which is may become null and void when the UK leaves the EU.

In the US the government has expressed similar ideas, and the hugely important [Section 230 of the Communications Decency Act](https://www.eff.org/issues/cda230) is in grave danger of being struck down by the current administration. Both governments have singled out blogging sites such as WordPress.com as well as communication platforms like Whatsapp to accuse them of providing "a secret place for terrorists to communicate with each other". [Evening Standard, March 26, 2017](https://www.standard.co.uk/news/politics/whatsapp-encryption-is-totally-unacceptable-says-home-secretary-amber-rudd-a3499416.html)

The government have suggested that intermediaries should remove extremist content within minutes of it going online, or even [stop it getting online in the first place](http://www.independent.co.uk/news/uk/home-news/isis-propaganda-online-terrorists-extremists-encrypted-apps-attacks-whatsapp-telegram-amber-rudd-a7871866.html) but attempting a technological solution is fraught with pitfalls. Firstly, that extremists and other bad actors will simple move onto other platforms where such controls are not in place - even as far as [creating their own messaging app](http://www.newsweek.com/isis-creates-its-own-secure-messaging-app-415565). Secondly, there is a danger that legitimate content will be inadvertently (or even deliberately) targeted.

And there is the larger danger of what will constitute 'bad' content. The decentralised, global nature of the internet means that there are many fuzzy edges between the laws of different countries. One country may ban certain types of speech, while they may be accepted in another country. Who decides when content should be published, and where? It is easy to see such fuzzy legalities being used to crack down on legitimate protest which a government may not like.

## The Web Matters position

While it is clear that there are huge problems to tackle online with regard to hate speech, counterfeiting, and a host of other crimes, intermediaries should not be held liable for the content of data travelling through or resting in their systems. Relying on technological solutions which are error-prone, inconsistently applied, easily circumvented and carry large risks of stifling genuine free speech, is a recipe for disaster.